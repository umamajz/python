# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11cXXr0cpihRrxcMnYcuS0jgyTGTogaP0


"""


"""B"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms

class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder1 = nn.Sequential(
            nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1),
            nn.ReLU(True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(8, 8, kernel_size=3, stride=1, padding=1),
            nn.ReLU(True),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.encoder2 = nn.Sequential(
            nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1),
            nn.ReLU(True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(8, 8, kernel_size=3, stride=1, padding=1),
            nn.ReLU(True),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.decoder1 = nn.Sequential(
            nn.ConvTranspose2d(8, 16, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.ReLU(True),
            nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.ReLU(True),
            nn.ConvTranspose2d(8, 3, kernel_size=3, stride=1, padding=1),
            nn.Sigmoid()
        )
        self.decoder2 = nn.Sequential(
            nn.ConvTranspose2d(8, 16, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.ReLU(True),
            nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.ReLU(True),
            nn.ConvTranspose2d(8, 3, kernel_size=3, stride=1, padding=1),
            nn.Sigmoid()
        )
        self.fc1 = nn.Linear(16 * 8 * 8, 128)
        self.fc2 = nn.Linear(128, 1)

def forward(self, x1, x2):
        x1 = self.encoder1(x1)
        x2 = self.encoder2(x2)
        x = torch.cat((x1, x2), dim=1)
        x = self.decoder1(x)
        x = self.decoder2(x)
        x = x.view(x.size(0), -1)
        x = self.fc1(x)
        x = nn.functional.relu(x)
        x = self.fc2(x)
        return x

from PIL import Image
import numpy as np

image_path1 = '/content/image1.png'
image_path2 = '/content/image2.png'
image1 = Image.open(image_path1).convert('RGB')
image2 = Image.open(image_path2).convert('RGB')
image1 = np.array(image1)
image2 = np.array(image2)
image1 = torch.from_numpy(image1).type(torch.FloatTensor)
image2 = torch.from_numpy(image2).type(torch.FloatTensor)
image1 = np.transpose(image1, (2, 0, 1))
image2 = np.transpose(image2, (2, 0, 1))
image1 = np.expand_dims(image1, axis=0)
image2 = np.expand_dims(image2, axis=0)

learning_rate = 0.001

# Define loss function and optimizer
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

print(image1_tensor.shape)
print(image2_tensor.shape)

num_epochs = 10

for epoch in range(num_epochs):
    # Convert numpy arrays to PyTorch tensors
    image1_tensor = torch.from_numpy(image1)
    image2_tensor = torch.from_numpy(image2)


    # Reshape input tensors to have the correct dimensions
    #image1_tensor = torch.from_numpy(image1).unsqueeze(0)
    #image2_tensor = torch.from_numpy(image2).unsqueeze(0)


    # Forward pass
    outputs = model(image1_tensor, image2_tensor)

    # Compute loss
    loss = criterion(outputs, image1_tensor)

    # Backward pass and optimize
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    # Print loss
    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))

